# Run Log: 2026-02-04 17:20

## Focus
Issue #20: [Feature] Add local model fallback with Ollama

## Changes
- `assistant/config.py`:
  - Added `OLLAMA_HOST` (default: http://localhost:11434)
  - Added `OLLAMA_MODEL` (default: llama3.2:3b)
  - Added `OLLAMA_ENABLED` (default: true)
  - Added `OLLAMA_TIMEOUT` (default: 120s)

- `assistant/server/services/ollama.py` (NEW):
  - `OllamaClient` class with health checks, model listing, chat API
  - `OllamaModelInfo` dataclass with tool support detection
  - `OllamaStatus` enum (UNKNOWN, AVAILABLE, UNAVAILABLE, NO_MODELS)
  - Streaming and non-streaming chat support
  - Result caching for health checks (30s)
  - `get_ollama_client()` singleton getter
  - `check_ollama_available()` convenience function

- `assistant/server/services/degradation.py`:
  - Added `ollama` to API health tracking
  - Added `CLOUD_UNAVAILABLE` mode (both cloud APIs down, Ollama available)
  - Added `LOCAL_ONLY` mode (user requested local-only)
  - Added `set_local_only_mode()` method
  - Updated `get_preferred_api()` to include Ollama in fallback chain
  - Updated `reset_api_health()` to include Ollama

- `assistant/server/routes/chat.py`:
  - Added `call_ollama_api()` function for non-streaming chat
  - Added `stream_ollama_response()` generator for streaming
  - Updated chat endpoint with Ollama fallback (cloud → ollama)
  - Updated streaming endpoint with Ollama fallback

- `assistant/server/routes/settings.py`:
  - Added Ollama settings to `SettingsUpdate` model
  - Added `GET /api/ollama/status` endpoint
  - Added `GET /api/ollama/models` endpoint
  - Added `POST /api/ollama/model` endpoint
  - Added `POST /api/ollama/local-only` endpoint
  - Updated `load_settings_on_startup()` to apply Ollama settings

- `assistant/server/services/settings.py`:
  - Added Ollama settings to DEFAULTS: `ollama_host`, `ollama_model`, `ollama_enabled`, `local_only_mode`
  - Added Ollama models to AVAILABLE_MODELS
  - Added `_parse_bool()` helper method
  - Updated `get_display_settings()` to include Ollama fields

- `assistant/server/routes/status.py`:
  - Updated `/api/health` to include `ollama_available`
  - Updated `/api/status` to include detailed model provider info
  - Added degradation mode and local-only mode to status

- `assistant/tests/test_ollama.py` (NEW):
  - 31 tests covering OllamaClient, OllamaModelInfo, DegradationService integration
  - Tests for health checks, model listing, chat, tool support detection
  - Tests for settings and config

- `assistant/tests/test_degradation.py`:
  - Updated tests for Ollama integration
  - Added tests for CLOUD_UNAVAILABLE mode
  - Added tests for Ollama fallback behavior

- `assistant/docs/OLLAMA_SETUP.md` (NEW):
  - Complete setup guide for Ollama integration
  - Installation instructions
  - Configuration options
  - Model recommendations
  - Troubleshooting guide

## Result
SUCCESS - Issue #20 implementation complete. All acceptance criteria met:
- [x] Ollama integration in config.py (OLLAMA_HOST, OLLAMA_MODEL settings)
- [x] New API client in server/services/ for Ollama API
- [x] Automatic fallback: Cloud API timeout/error → Try Ollama
- [x] Manual override: User can force local-only mode via settings
- [x] Model selection in settings UI (available local models)
- [x] Health check includes Ollama availability
- [x] Streaming support for Ollama responses
- [x] Tool calling support if model supports it (or graceful degradation)
- [x] Tests for Ollama integration (31 new tests, 708 total)
- [x] Documentation for Ollama setup

## How to Test
```bash
# Install Ollama
brew install ollama
ollama serve
ollama pull llama3.2:3b

# Check status
curl http://127.0.0.1:8080/api/ollama/status

# Enable local-only mode
curl -X POST http://127.0.0.1:8080/api/ollama/local-only \
  -H "Content-Type: application/json" \
  -d '{"enabled": true}'

# Chat with local model
curl -X POST http://127.0.0.1:8080/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Hello!"}'

# Run tests
cd assistant
python3 -m pytest tests/test_ollama.py -v  # 31 tests
python3 -m pytest tests/ -v                 # 708 total
```

## Next
Issue #20 labeled `needs-verification` for Criticizer verification.
